{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "import OpenEXR\n",
    "import array\n",
    "import Imath\n",
    "from inference import Inferencer\n",
    "\n",
    "\n",
    "def draw_point_cloud(color, depth, camera_intrinsics, use_mask = False, use_inpainting = False, scale = 1000.0, inpainting_radius = 5, fault_depth_limit = 0.2, epsilon = 0.01):\n",
    "    \"\"\"\n",
    "    Given the depth image, return the point cloud in open3d format.\n",
    "    The code is adapted from [graspnet.py] in the [graspnetAPI] repository.\n",
    "    \"\"\"\n",
    "    d = depth.copy()\n",
    "    c = color.copy() / 255.0\n",
    "    \n",
    "    if use_inpainting:\n",
    "        fault_mask = (d < fault_depth_limit * scale)\n",
    "        d[fault_mask] = 0\n",
    "        inpainting_mask = (np.abs(d) < epsilon * scale).astype(np.uint8)  \n",
    "        d = cv2.inpaint(d, inpainting_mask, inpainting_radius, cv2.INPAINT_NS)\n",
    "\n",
    "    fx, fy = camera_intrinsics[0, 0], camera_intrinsics[1, 1]\n",
    "    cx, cy = camera_intrinsics[0, 2], camera_intrinsics[1, 2]\n",
    "\n",
    "    xmap, ymap = np.arange(d.shape[1]), np.arange(d.shape[0])\n",
    "    xmap, ymap = np.meshgrid(xmap, ymap)\n",
    "\n",
    "    points_z = d / scale\n",
    "    points_x = (xmap - cx) / fx * points_z\n",
    "    points_y = (ymap - cy) / fy * points_z\n",
    "    points = np.stack([points_x, points_y, points_z], axis = -1)\n",
    "\n",
    "    if use_mask:\n",
    "        mask = (points_z > 0)\n",
    "        points = points[mask]\n",
    "        c = c[mask]\n",
    "    else:\n",
    "        points = points.reshape((-1, 3))\n",
    "        c = c.reshape((-1, 3))\n",
    "    cloud = o3d.geometry.PointCloud()\n",
    "    cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    cloud.colors = o3d.utility.Vector3dVector(c)\n",
    "    return cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280)\n"
     ]
    }
   ],
   "source": [
    "sample_root = 'data/scene21/2'\n",
    "\n",
    "rgb = np.array(Image.open(sample_root + '/rgb1.png'), dtype = np.float32)\n",
    "depth = np.array(Image.open(sample_root + '/depth1.png'), dtype = np.float32)\n",
    "depth_gt = np.array(Image.open(sample_root + '/depth1-gt.png'), dtype = np.float32)\n",
    "\n",
    "print(depth.shape)\n",
    "\n",
    "depth = depth / 1000\n",
    "depth_gt = depth_gt / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = cv2.imread('000000080-transparent-depth-img.exr',  cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)[:, :, 0]\n",
    "depth_gt = cv2.imread('000000080-opaque-depth-img.exr',  cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)[:, :, 0] \n",
    "rgb = np.array(Image.open('000000080-transparent-rgb-img.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = cv2.imread('scene12_IMG_DepthMap.tif',  cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)\n",
    "depth_gt = cv2.imread('scene12-gt_IMG_DepthMap.tif',  cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)\n",
    "rgb = np.array(Image.open('secondcamera.jpg'))\n",
    "#rgb = np.array([rgb, rgb, rgb])\n",
    "#rgb = np.transpose(rgb, (1, 2, 0))\n",
    "\n",
    "depth = depth / 1000\n",
    "depth_gt = depth_gt / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1680)\n",
      "1.6723491\n"
     ]
    }
   ],
   "source": [
    "print(depth.shape)\n",
    "\n",
    "print(np.amax(depth))\n",
    "#cv2.imshow('', rgb)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer = Inferencer()\n",
    "res, depth_n = inferencer.inference(np.copy(rgb), np.copy(depth), depth_coefficient = 3, inpainting = True)\n",
    "#res, depth_n = inferencer.inference(np.copy(rgb), np.copy(depth), depth_coefficient = 10, inpainting = True, target_size = (1680, 1200))\n",
    "\n",
    "cam_intrinsics = np.load('camIntrinsics-PhoXi.npy')\n",
    "#cam_intrinsics = np.load('camIntrinsics-clear.npy')\n",
    "\n",
    "#res = np.clip(res, 0.3, 1.0)\n",
    "#depth = np.clip(depth, 0.3, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_raw = draw_point_cloud(rgb, depth_n, cam_intrinsics, scale = 0.2)\n",
    "cloud = draw_point_cloud(rgb, res, cam_intrinsics, scale = 0.2)\n",
    "cloud_gt = draw_point_cloud(rgb, depth_gt, cam_intrinsics, scale = 0.2)\n",
    "\n",
    "frame = o3d.geometry.TriangleMesh.create_coordinate_frame(0.1)\n",
    "sphere = o3d.geometry.TriangleMesh.create_sphere(0.002,20).translate([0,0,0.490])\n",
    "o3d.visualization.draw_geometries([cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = o3d.visualization.VisualizerWithKeyCallback()\n",
    "vis.create_window()\n",
    "\n",
    "vis.add_geometry(cloud_raw)\n",
    "#vis.add_geometry(cloud)\n",
    "\n",
    "def key_callback(key):\n",
    "    #vis.remove_geometry(cloud_raw)\n",
    "    vis.add_geometry(cloud)\n",
    "    vis.update_renderer()\n",
    "\n",
    "#render_option = vis.get_render_option()\n",
    "#render_option.point_size = 0.5\n",
    "\n",
    "vis.register_key_callback(ord('1'), key_callback)\n",
    "\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
